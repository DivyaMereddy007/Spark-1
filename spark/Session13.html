<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Session13 - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta name="robots" content="nofollow">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/img/favicon.ico"/>
<script>window.settings = {"enableUsageDeliveryConfiguration":false,"enableNotebookNotifications":true,"enableSshKeyUI":false,"defaultInteractivePricePerDBU":0.4,"enableClusterMetricsUI":true,"allowWhitelistedIframeDomains":true,"enableOnDemandClusterType":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","enableJobsPrefetching":true,"workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/index.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableReservoirTableUI":true,"enableClearStateFeature":true,"dbcForumURL":"http://forums.databricks.com/","enableProtoClusterInfoDeltaPublisher":true,"enableAttachExistingCluster":true,"resetJobListOnConnect":true,"serverlessDefaultSparkVersion":"latest-stable-scala2.11","maxCustomTags":45,"serverlessDefaultMaxWorkers":20,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"support_ssh":false,"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","support_cluster_tags":false,"container_memory_mb":6000,"node_instance_type":{"instance_type_id":"r3.2xlarge","provider":"AWS","local_disk_size_gb":160,"compute_units":26.0,"number_of_ips":14,"local_disks":1,"reserved_compute_units":3.64,"gpus":0,"memory_mb":62464,"num_cores":8,"local_disk_type":"AHCI","max_attachable_disks":0,"supported_disk_types":[{"ebs_volume_type":"GENERAL_PURPOSE_SSD"},{"ebs_volume_type":"THROUGHPUT_OPTIMIZED_HDD"}],"reserved_memory_mb":4800},"memory_mb":6144,"is_hidden":false,"category":"Community Edition","num_cores":0.88,"support_port_forwarding":false,"support_ebs_volumes":false,"is_deprecated":false}],"default_node_type_id":"dev-tier-node"},"sqlAclsDisabledMap":{"spark.databricks.acl.enabled":"false","spark.databricks.acl.sqlOnly":"false"},"enableDatabaseSupportClusterChoice":true,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"serverlessClusterProductName":"Serverless Pool","showS3TableImportOption":true,"maxEbsVolumesPerInstance":10,"enableRStudioUI":false,"isAdmin":true,"deltaProcessingBatchSize":1000,"timerUpdateQueueLength":100,"sqlAclsEnabledMap":{"spark.databricks.acl.enabled":"true","spark.databricks.acl.sqlOnly":"true"},"enableLargeResultDownload":true,"maxElasticDiskCapacityGB":5000,"serverlessDefaultMinWorkers":2,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableCustomSpotPricingUIByTier":false,"serverlessClustersEnabled":false,"enableWorkspaceBrowserSorting":true,"enableSentryLogging":true,"enableFindAndReplace":true,"disallowUrlImportExceptFromDocs":false,"defaultStandardClusterModel":{"cluster_name":"","node_type_id":"dev-tier-node","spark_version":"3.5.x-scala2.11","num_workers":0,"aws_attributes":{"first_on_demand":0,"availability":"ON_DEMAND","zone_id":"us-west-2c","spot_bid_price_percent":100},"autotermination_minutes":120,"default_tags":{"Vendor":"Databricks","Creator":"muhammadzak.ml@gmail.com","ClusterName":null,"ClusterId":"<Generated after creation>"}},"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":true,"enableBitbucketCloud":true,"shouldShowCommandStatus":true,"createTableInNotebookS3Link":{"url":"https://docs.databricks.com/_static/notebooks/data-import/s3.html","displayName":"S3","workspaceFileName":"S3 Example"},"sanitizeHtmlResult":true,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"enableNewClustersCreate":true,"clusters":true,"allowRunOnPendingClusters":true,"useAutoscalingByDefault":false,"enableAzureToolbar":false,"fileStoreBase":"FileStore","enableEmailInAzure":false,"enableRLibraries":true,"enableTableAclsConfig":false,"enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":true,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":false,"checkBeforeAddingAadUser":false,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"createTableInNotebookDBFSLink":{"url":"https://docs.databricks.com/_static/notebooks/data-import/dbfs.html","displayName":"DBFS","workspaceFileName":"DBFS Example"},"perClusterAutoterminationEnabled":false,"enableNotebookCommandNumbers":true,"allowStyleInSanitizedHtml":true,"sparkVersions":[{"key":"1.6.3-db2-hadoop2-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-aba860a0ffce4f3471fb14aefdcb1d768ac66a53a5ad884c48745ef98aeb9d67","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db6-rc-scala2.10","displayName":"Spark 2.1.1-db6 RC (Scala 2.10)","packageLabel":"spark-image-4efc0c94e152791782f2cb865ac1eb3c11985a2671a77e6ef930f9718851459d","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-rc-scala2.10","displayName":"3.0 RC (Scala 2.10)","packageLabel":"spark-image-2fdca45e0fcac7081823a5faef4f25d6fc909d11c44eca82e1dd18e9d2ef2859","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-gpu-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-22756288786762d246bac1381e4f44610a4c2c3135c717c5ac3661822a723f1c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.1-db5-rc-scala2.11","displayName":"Spark 2.1.1-db5 RC (Scala 2.11)","packageLabel":"spark-image-7ce07ae16a775d917d6748d2075807565c157286f4f5957c1b77275b3b2a9bc4","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db5-scala2.11","displayName":"Spark 2.1.1-db5 (Scala 2.11)","packageLabel":"spark-image-7ce07ae16a775d917d6748d2075807565c157286f4f5957c1b77275b3b2a9bc4","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-scala2.10","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-86a9b375074f5afad339e70230ec0ec265c4cefbd280844785fab3bcde5869f9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1, deprecated)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.2.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-cdfb5c6299de6a2f4f5b75e8def2d11faa2026a8354185434873ec4612916663","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.1-db6-scala2.10","displayName":"Spark 2.1.1-db6 (Scala 2.10)","packageLabel":"spark-image-4efc0c94e152791782f2cb865ac1eb3c11985a2671a77e6ef930f9718851459d","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db2-scala2.11","displayName":"Spark 2.1.0-db2 (Scala 2.11)","packageLabel":"spark-image-267c4490a3ab8a39acdbbd9f1d36f6decdecebf013e30dd677faff50f1d9cf8b","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-scala2.11","displayName":"4.0 (includes Apache Spark 2.3.0, Scala 2.11)","packageLabel":"spark-image-fc9368293e1b3b6c37181d7af3123a4b9de5f7fa03cfd6dfaa038753256380c9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.5.x-rc-scala2.11","displayName":"3.5.3 RC (Scala 2.11)","packageLabel":"spark-image-186aba6ea410062ae0d6aa00426bd49fc7173ed2f0f9a81e8b6966ed509bcca6","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.x-gpu-scala2.11","displayName":"Spark 2.1 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-d613235f93e0f29838beb2079a958c02a192ed67a502192bc67a8a5f2fb37f35","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-rc-scala2.11","displayName":"4.0.1 RC (Scala 2.11)","packageLabel":"spark-image-09b7fd45c8c0db3c626e4717d345c47984008d3d9fc1b3364b22392cb34c7a9a","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"latest-stable-gpu-scala2.11","displayName":"Latest stable (GPU, Scala 2.11)","packageLabel":"spark-image-7a1e78fbfc4d1645e7478daa28377389b900aec38764df46bd836c1a9925499b","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-scala2.11","displayName":"3.4 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-f91cb0b3822c6641a9d346ef6c149118fb859b5e511ee01c31e958892ba23c7a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db3-scala2.10","displayName":"Spark 2.0.2-db3 (Scala 2.10)","packageLabel":"spark-image-584091dedb690de20e8cf22d9e02fdcce1281edda99eedb441a418d50e28088f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.2.x-scala2.10","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-e50cbe4c0b0ad46930872eff4b69665890fd6a170e2b1a3e48c1cdea5823fd86","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-experimental-scala2.10","displayName":"Latest experimental (Scala 2.10)","packageLabel":"spark-image-ec81b6840af02ee2321dd8dfe2587437bbcddf024d4ae287f326a98fac406a6c","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-rc-gpu-scala2.11","displayName":"3.4.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-1749b69f7f6bfeabbdfe5ab4844cf094cdbdee102abbf171bc1192831d1c71ba","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-gpu-scala2.11","displayName":"4.0 (includes Apache Spark 2.3.0, GPU, Scala 2.11)","packageLabel":"spark-image-b543c0700f83413b0055359ea9feaf285f2e2f3350fb7f301ea0e18b018b5cb5","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.0-db1-scala2.11","displayName":"Spark 2.1.0-db1 (Scala 2.11)","packageLabel":"spark-image-e8ad5b72cf0f899dcf2b4720c1f572ab0e87a311d6113b943b4e1d4a7edb77eb","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db4-rc-scala2.10","displayName":"Spark 2.1.1-db4 RC (Scala 2.10)","packageLabel":"spark-image-0112f566715b00d5aceb1b98543285bcb3a0f38174b86abd1c096c3e861043eb","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db5-rc-scala2.10","displayName":"Spark 2.1.1-db5 RC (Scala 2.10)","packageLabel":"spark-image-07da7d24ad964d7a43f53bd9feac55de7df890ef6e5f6bac8975fb7aa3e2a0a7","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db4-scala2.11","displayName":"Spark 2.1.1-db4 (Scala 2.11)","packageLabel":"spark-image-62365f2d91529bc1128d8968f33d07f5b8d75cf7305de9455bc970e6e1fecbb4","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-scala2.11","displayName":"Latest RC (4.1 snapshot, Scala 2.11)","packageLabel":"spark-image-1d92e35cba80ac52a0cabd35331596f170b82483f5dd263093531b9ff0145a7d","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"latest-stable-scala2.11","displayName":"Latest stable (Scala 2.11)","packageLabel":"spark-image-c919ecd682175957255cbc87041d82633406312f7b74e018e165c4fe94943b5f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.1-db6-rc-scala2.11","displayName":"Spark 2.1.1-db6 RC (Scala 2.11)","packageLabel":"spark-image-0067951c626cad90625cce4d2dcf3e00a1029375f8e5470d2330036d0d3c505f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.0-db2-scala2.10","displayName":"Spark 2.1.0-db2 (Scala 2.10)","packageLabel":"spark-image-a2ca4f6b58c95f78dca91b1340305ab3fe32673bd894da2fa8e1dc8a9f8d0478","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-rc-scala2.11","displayName":"3.3.3 RC (Scala 2.11)","packageLabel":"spark-image-0d4f1222260f2cce27b6eccc0397cf5f53c06c21dcd234ac4ab2a5496154aad9","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-rc-scala2.11","displayName":"3.4.3 RC (Scala 2.11)","packageLabel":"spark-image-a247082e38050ffc107b8185543dce07ca17ae6ff8c89de520821fe06a47fbce","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db4-scala2.11","displayName":"Spark 2.0.2-db4 (Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-gpu-scala2.11","displayName":"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-968b89f1d0ec32e1ee4dacd04838cae25ef44370a441224177a37980d539d83a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"3.3.x-rc-gpu-scala2.11","displayName":"3.3.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-4381939c7bc02e4e4aa1d98e6de177939671f38a1d37ea0548e71be1f26f227d","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"next-major-version-scala2.11","displayName":"Next major version (4.0 snapshot, Scala 2.11)","packageLabel":"spark-image-04bb47b0bae8165f760972376ce05083bc6102645f3f3851cd1cdf9cba13d6fe","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.1-db4-rc-scala2.11","displayName":"Spark 2.1.1-db4 RC (Scala 2.11)","packageLabel":"spark-image-62365f2d91529bc1128d8968f33d07f5b8d75cf7305de9455bc970e6e1fecbb4","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-eaa8d9b990015a14e032fb2e2e15be0b8d5af9627cd01d855df728b67969d5d9","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.3-db2-hadoop1-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-14112ea0645bea94333a571a150819ce85573cf5541167d905b7e6588645cf3b","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"4.0.x-rc-gpu-scala2.11","displayName":"4.0.1 RC (GPU, Scala 2.11)","packageLabel":"spark-image-75a541d19e7e7a319070d821295d375179d46b5601ce2525655c8a1f4781b541","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-scala2.10","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.10)","packageLabel":"spark-image-5e4f1f2feb631875a6036dffb069ec14b436939b5efe0ecb3ff8220c835298d6","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-rc-scala2.10","displayName":"3.3.3 RC (Scala 2.10)","packageLabel":"spark-image-03f2fb923dd09bd671fd759bba274a73b49cc95583b3cd48a5b11e38c3dc780d","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db4-scala2.10","displayName":"Spark 2.1.1-db4 (Scala 2.10)","packageLabel":"spark-image-0112f566715b00d5aceb1b98543285bcb3a0f38174b86abd1c096c3e861043eb","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-scala2.10","displayName":"Latest RC (Scala 2.10)","packageLabel":"spark-image-ec81b6840af02ee2321dd8dfe2587437bbcddf024d4ae287f326a98fac406a6c","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-stable-scala2.10","displayName":"Latest stable (Scala 2.10)","packageLabel":"spark-image-5e4f1f2feb631875a6036dffb069ec14b436939b5efe0ecb3ff8220c835298d6","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-rc-scala2.10","displayName":"3.4.3 RC (Scala 2.10)","packageLabel":"spark-image-7b1c8193e287eef3e118628cc05a1cdb9bcce1179e1eefda2fcf8abe78bee0ca","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db4-scala2.10","displayName":"Spark 2.0.2-db4 (Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"3.1.x-rc-scala2.10","displayName":"3.1 RC (Scala 2.10)","packageLabel":"spark-image-c6b477859faf291f56ac2dcbe6f6693d60e403c12dfcac58892b4014614363c3","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db5-scala2.10","displayName":"Spark 2.1.1-db5 (Scala 2.10)","packageLabel":"spark-image-07da7d24ad964d7a43f53bd9feac55de7df890ef6e5f6bac8975fb7aa3e2a0a7","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-gpu-scala2.11","displayName":"3.4 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-66d1366768039140a9f5409f3bab414cb7477ebd8d4bbf8b32cb885120f9f705","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1, deprecated)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"latest-experimental-gpu-scala2.11","displayName":"Latest experimental (4.1 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-289977189631a0eb8732ec581a609b7f659944816731752409eb0787db1847ac","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.2.x-rc-scala2.11","displayName":"3.2 RC (Scala 2.11)","packageLabel":"spark-image-3b22b5c8d5577281bcca8dd6ef07553fb32b3b99ab977f8bdb7238f850ece887","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.2.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-2fdca45e0fcac7081823a5faef4f25d6fc909d11c44eca82e1dd18e9d2ef2859","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.0.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-cdfb5c6299de6a2f4f5b75e8def2d11faa2026a8354185434873ec4612916663","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.x-scala2.10","displayName":"Spark 2.1 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-177f3f02a6a3432d30068332dc857b9161345bdd2ee8a2d2de05bb05cb4b0f4c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.1.x-scala2.11","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-0d3a99d46a4c55642850b5eba9aad3b56ffb9adbe8c8893403eba834399960fc","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db3-scala2.10","displayName":"Spark 2.1.0-db3 (Scala 2.10)","packageLabel":"spark-image-25a17d070af155f10c4232dcc6248e36a2eb48c24f8d4fc00f34041b86bd1626","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-rc-scala2.11","displayName":"3.0 RC (Scala 2.11)","packageLabel":"spark-image-cdfb5c6299de6a2f4f5b75e8def2d11faa2026a8354185434873ec4612916663","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-rc-gpu-scala2.11","displayName":"3.5.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-a36046dce3a45e476fe9f7f4ed0f5a5ea58d7adb658a128d42c1d56bcfa8ecbf","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.1.x-scala2.10","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-c6b477859faf291f56ac2dcbe6f6693d60e403c12dfcac58892b4014614363c3","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.3.x-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-46cc39a9afa43fbd7bfa9f4f5ed8d23f658cd0b0d74208627243222ae0d22f8d","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"next-major-version-gpu-scala2.11","displayName":"Next major version (4.0 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-41e21a0db3b77bc857f10358917ccbf5fbd85290e8429c2176a5fc7a29ce4f18","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-gpu-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, GPU, Scala 2.11)","packageLabel":"spark-image-7a1e78fbfc4d1645e7478daa28377389b900aec38764df46bd836c1a9925499b","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1, deprecated)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db3-scala2.11","displayName":"Spark 2.0.2-db3 (Scala 2.11)","packageLabel":"spark-image-7fd7aaa89d55692e429115ae7eac3b1a1dc4de705d50510995f34306b39c2397","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db6-scala2.11","displayName":"Spark 2.1.1-db6 (Scala 2.11)","packageLabel":"spark-image-0067951c626cad90625cce4d2dcf3e00a1029375f8e5470d2330036d0d3c505f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-d50af1032799546b8ccbeeb76889a20c819ebc2a0e68ea20920cb30d3895d3ae","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.11)","packageLabel":"spark-image-c919ecd682175957255cbc87041d82633406312f7b74e018e165c4fe94943b5f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.1.x-rc-scala2.11","displayName":"3.1 RC (Scala 2.11)","packageLabel":"spark-image-0d3a99d46a4c55642850b5eba9aad3b56ffb9adbe8c8893403eba834399960fc","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"latest-experimental-scala2.11","displayName":"Latest experimental (4.1 snapshot, Scala 2.11)","packageLabel":"spark-image-1d92e35cba80ac52a0cabd35331596f170b82483f5dd263093531b9ff0145a7d","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.2.x-scala2.11","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-3b22b5c8d5577281bcca8dd6ef07553fb32b3b99ab977f8bdb7238f850ece887","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.x-scala2.11","displayName":"Spark 2.1 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-fdad9ef557700d7a8b6bde86feccbcc3c71d1acdc838b0fd299bd19956b1076e","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db1-scala2.10","displayName":"Spark 2.1.0-db1 (Scala 2.10)","packageLabel":"spark-image-f0ab82a5deb7908e0d159e9af066ba05fb56e1edb35bdad41b7ad2fd62a9b546","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-2fdca45e0fcac7081823a5faef4f25d6fc909d11c44eca82e1dd18e9d2ef2859","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.0-db3-scala2.11","displayName":"Spark 2.1.0-db3 (Scala 2.11)","packageLabel":"spark-image-ccbc6b73f158e2001fc1fb8c827bfdde425d8bd6d65cb7b3269784c28bb72c16","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-gpu-scala2.11","displayName":"Latest RC (4.1 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-289977189631a0eb8732ec581a609b7f659944816731752409eb0787db1847ac","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-rc-scala2.10","displayName":"3.5.3 RC (Scala 2.10)","packageLabel":"spark-image-a344fae4e7b21a6bee7cc96ee0f4a2ec466164947b148b95b24ab28dc3b53958","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.4.x-scala2.10","displayName":"3.4 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-867d7300605c0c54b2b1394d1bba7b88b28ed5841b3575253cded34db6ce6454","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.2.x-rc-scala2.10","displayName":"3.2 RC (Scala 2.10)","packageLabel":"spark-image-e50cbe4c0b0ad46930872eff4b69665890fd6a170e2b1a3e48c1cdea5823fd86","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]}],"enablePresentationMode":false,"enableClearStateAndRunAll":true,"enableTableAclsByTier":false,"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"enableUserVisibleDefaultTags":true,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"jobsUnreachableThresholdMillis":60000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"createTableInNotebookImportedFileLink":{"url":"https://docs.databricks.com/_static/notebooks/data-import/imported-file.html","displayName":"Imported File","workspaceFileName":"Imported File Example"},"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","tableAclsDisabledMap":{"spark.databricks.acl.dfAclsEnabled":"false"},"driverStdoutFilePrefix":"stdout","showDbuPricing":true,"databricksDocsBaseHostname":"docs.databricks.com","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"i3.4xlarge":4,"class-node":1,"m4.2xlarge":1.5,"Standard_D11_v2":0.5,"r4.xlarge":1,"m4.4xlarge":3,"Standard_DS5_v2":3,"Standard_D2s_v3":0.5,"Standard_DS4_v2_Promo":1.5,"Standard_DS14":4,"Standard_DS11_v2_Promo":0.5,"r4.16xlarge":16,"Standard_DS11":0.5,"Standard_D2_v3":0.5,"Standard_DS14_v2_Promo":4,"Standard_D64s_v3":12,"p2.8xlarge":16,"m4.10xlarge":8,"Standard_D8s_v3":1.5,"Standard_E32s_v3":8,"Standard_DS3":0.75,"Standard_DS2_v2":0.5,"r3.8xlarge":8,"r4.4xlarge":4,"dev-tier-node":1,"Standard_L8s":2,"Standard_D13_v2":2,"Standard_DS13_v2_Promo":2,"Standard_E4s_v3":1,"Standard_D3_v2":0.75,"Standard_DS15_v2":5,"Standard_D16s_v3":3,"Standard_D5_v2":3,"Standard_E8s_v3":2,"Standard_DS2_v2_Promo":0.5,"c3.8xlarge":4,"Standard_D4_v3":0.75,"Standard_E2s_v3":0.5,"Standard_D32_v3":6,"Standard_DS3_v2":0.75,"r3.4xlarge":4,"Standard_DS4":1.5,"i2.4xlarge":6,"Standard_DS3_v2_Promo":0.75,"m4.xlarge":0.75,"r4.8xlarge":8,"Standard_D14_v2":4,"Standard_H16":4,"Standard_DS14_v2":4,"r4.large":0.5,"Standard_D15_v2":5,"Standard_DS12":1,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"Standard_D12_v2":1,"i3.large":0.75,"memory-optimized":1,"m4.large":0.4,"Standard_D16_v3":3,"Standard_F4s":0.5,"p2.16xlarge":24,"i3.8xlarge":8,"Standard_D32s_v3":6,"i3.16xlarge":16,"Standard_DS12_v2":1,"Standard_L32s":8,"Standard_D4s_v3":0.75,"Standard_DS13":2,"Standard_DS11_v2":0.5,"Standard_DS12_v2_Promo":1,"Standard_DS13_v2":2,"c3.2xlarge":1,"Standard_L4s":1,"Standard_F16s":2,"c4.2xlarge":1,"Standard_L16s":4,"i2.xlarge":1.5,"Standard_DS2":0.5,"compute-optimized":1,"c4.4xlarge":2,"Standard_DS5_v2_Promo":3,"Standard_D64_v3":12,"Standard_D2_v2":0.5,"Standard_D8_v3":1.5,"i3.2xlarge":2,"Standard_E16s_v3":4,"Standard_F8s":1,"c3.4xlarge":2,"g2.2xlarge":1.5,"p2.xlarge":2,"m4.16xlarge":12,"Standard_DS4_v2":1.5,"c4.8xlarge":4,"i3.xlarge":1,"r3.xlarge":1,"r4.2xlarge":2,"i2.8xlarge":12},"tableFilesBaseFolder":"/tables","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableClusterAppsUIOnServerless":false,"enableEBSVolumesUI":false,"homePageWelcomeMessage":"Welcome to ","metastoreServiceRowLimit":1000000,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":true,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.68.34","accountsLimit":3,"enableSparkEnvironmentVariables":true,"enableX509Authentication":false,"useAADLogin":false,"enableStructuredStreamingNbOptimizations":true,"enableNotebookGitBranching":true,"local":false,"enableNotebookLazyRenderWrapper":false,"enableClusterAutoScalingForJobs":true,"enableStrongPassword":false,"showReleaseNote":true,"displayDefaultContainerMemoryGB":6,"broadenedEditPermission":false,"disableS3TableImport":false,"enableArrayParamsEdit":true,"deploymentMode":"production","useSpotForWorkers":true,"removePasswordInAccountSettings":false,"preferStartTerminatedCluster":false,"enableUserInviteWorkflow":true,"createTableConnectorOptionLinks":[{"url":"https://docs.databricks.com/_static/notebooks/redshift.html","displayName":"Amazon Redshift","workspaceFileName":"Amazon Redshift Example"},{"url":"https://docs.databricks.com/_static/notebooks/structured-streaming-kinesis.html","displayName":"Amazon Kinesis","workspaceFileName":"Amazon Kinesis Example"},{"url":"https://docs.databricks.com/_static/notebooks/data-import/jdbc.html","displayName":"JDBC","workspaceFileName":"JDBC Example"},{"url":"https://docs.databricks.com/_static/notebooks/cassandra.html","displayName":"Cassandra","workspaceFileName":"Cassandra Example"},{"url":"https://docs.databricks.com/_static/notebooks/structured-streaming-etl-kafka.html","displayName":"Kafka","workspaceFileName":"Kafka Example"},{"url":"https://docs.databricks.com/_static/notebooks/redis.html","displayName":"Redis","workspaceFileName":"Redis Example"},{"url":"https://docs.databricks.com/_static/notebooks/elasticsearch.html","displayName":"Elasticsearch","workspaceFileName":"Elasticsearch Example"}],"enableStaticNotebooks":true,"enableNewLineChart":true,"sandboxForUrlSandboxFrame":"allow-scripts allow-popups allow-popups-to-escape-sandbox allow-forms","enableCssTransitions":true,"serverlessEnableElasticDisk":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterEdit":true,"enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableSshKeyUIByTier":false,"enableCreateClusterOnAttach":true,"defaultAutomatedPricePerDBU":0.2,"enableNotebookGitVersioning":true,"defaultMinWorkers":2,"commandStatusDebounceMaxWait":1000,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"enableExperimentalCharts":false,"defaultMaxWorkers":8,"enableWorkspaceAclsConfig":false,"serverlessRunPythonAsLowPrivilegeUser":false,"dropzoneMaxFileSize":2047,"enableNewClustersList":true,"enableNewDashboardViews":true,"enableJobListPermissionFilter":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"enableSparkEnvironmentVariablesUI":false,"defaultSparkVersion":{"key":"3.5.x-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.11)","packageLabel":"spark-image-c919ecd682175957255cbc87041d82633406312f7b74e018e165c4fe94943b5f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},"enableNewLineChartParams":false,"deprecatedEnableStructuredDataAcls":false,"enableCustomSpotPricing":false,"enableRStudioFreeUI":false,"enableMountAclsConfig":false,"defaultAutoterminationMin":120,"useDevTierHomePage":true,"disableExportNotebook":false,"enableClusterClone":true,"enableNotebookLineNumbers":true,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","commandStatusDebounceInterval":100,"showSqlEndpoints":false,"enableNotebookDatasetInfoView":true,"defaultTagKeys":{"CLUSTER_NAME":"ClusterName","VENDOR":"Vendor","CLUSTER_TYPE":"ResourceClass","CREATOR":"Creator","CLUSTER_ID":"ClusterId"},"enableClusterAclsByTier":false,"databricksDocsBaseUrl":"https://docs.databricks.com/","azurePortalLink":"https://portal.azure.com","cloud":"AWS","customSparkVersionPrefix":"custom:","disallowAddingAdmins":true,"enableSparkConfUI":true,"enableClusterEventsUI":true,"featureTier":"DEVELOPER_BASIC_TIER","mavenCentralSearchEndpoint":"http://search.maven.org/solrsearch/select","defaultServerlessClusterModel":{"cluster_name":"","node_type_id":"i3.2xlarge","spark_version":"latest-stable-scala2.11","num_workers":null,"enable_jdbc_auto_start":true,"custom_tags":{"ResourceClass":"Serverless"},"autoscale":{"min_workers":2,"max_workers":20},"spark_conf":{"spark.databricks.cluster.profile":"serverless","spark.databricks.repl.allowedLanguages":"sql,python,r","spark.databricks.acl.enabled":"false","spark.databricks.acl.sqlOnly":"false"},"aws_attributes":{"ebs_volume_count":null,"availability":"ON_DEMAND","first_on_demand":1,"ebs_volume_type":null,"spot_bid_price_percent":100,"zone_id":"us-west-2c","ebs_volume_size":null},"autotermination_minutes":0,"enable_elastic_disk":false,"default_tags":{"Vendor":"Databricks","Creator":"muhammadzak.ml@gmail.com","ClusterName":null,"ClusterId":"<Generated after creation>"}},"enableOrgSwitcherUI":true,"bitbucketCloudBaseApiV2Url":"https://api.bitbucket.org/2.0","clustersLimit":1,"enableJdbcImport":true,"enableClusterAppsUIOnNormalClusters":false,"enableElasticDisk":false,"logfiles":"logfiles/","enableRelativeNotebookLinks":true,"enableMultiSelect":true,"homePageLogo":"login/databricks_logoTM_rgb_TM.svg","enableWebappSharding":true,"enableNotebookParamsEdit":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"separateTableForJobClusters":true,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"enableRServerless":true,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"showVersion":true,"serverlessClustersByDefault":false,"enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"","clusterTagReservedPrefixes":[],"tableAclsEnabledMap":{"spark.databricks.acl.dfAclsEnabled":"true"},"showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","databricksDocsNotebookPathPrefix":"^https://docs\\.databricks\\.com/_static/notebooks/.+$","serverlessAttachEbsVolumesByDefault":false,"enableTokensConfig":false,"allowFeedbackForumAccess":true,"enablePythonVersionUI":true,"enableImportFromUrl":true,"allowDisplayHtmlByUrl":true,"enableTokens":false,"enableMiniClusters":true,"enableNewJobList":true,"enableDebugUI":false,"enableStreamingMetricsDashboard":true,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"loginLogo":"/login/databricks_logoTM_rgb_TM.svg","useStandardTierUpgradeTooltips":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/","enableSpotClusterType":true,"enableSparkPackages":true,"checkAadUserInWorkspaceTenant":false,"dynamicSparkVersions":true,"useIframeForHtmlResult":false,"enableClusterTagsUIByTier":false,"enableUserPromptForPendingRpc":true,"enableNotebookHistoryUI":true,"addWhitespaceAfterLastNotebookCell":true,"enableClusterLoggingUI":true,"enableDatabaseDropdownInTableUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":false,"enableFolderHtmlExport":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"enableClusterStart":false,"maxImportFileVersion":5,"enableEBSVolumesUIByTier":false,"enableTableAclService":true,"removeSubCommandCodeWhenExport":true,"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","maxAutoterminationMinutes":10000,"showResultsFromExternalSearchEngine":true,"autoterminateClustersByDefault":true,"notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":false,"showForgotPasswordLink":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"minAutoterminationMinutes":10,"accounts":true,"useOnDemandClustersByDefault":true,"enableNewProgressReportUI":true,"enableAutoCreateUserUI":true,"defaultCoresPerContainer":4,"showTerminationReason":true,"enableNewClustersGet":true,"showPricePerDBU":false,"showSqlProxyUI":true,"enableNotebookErrorHighlighting":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":463637603480127,"name":"Session13","language":"scala","commands":[{"version":"CommandV1","origId":463637603480128,"guid":"c167b61d-266e-4496-bdae-2b6a43093ade","subtype":"command","commandType":"auto","position":1.0,"command":"val raw_df = spark.read.options(Map({\"header\"->\"true\"},{\"inferSchema\" -> \"true\"})).csv(\"/mnt/learningai1/airbnb.csv\")\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">raw_df: org.apache.spark.sql.DataFrame = [id: int, name: string ... 19 more fields]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[{"name":"raw_df","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"id","type":"integer","nullable":true,"metadata":{}},{"name":"name","type":"string","nullable":true,"metadata":{}},{"name":"space","type":"string","nullable":true,"metadata":{}},{"name":"price","type":"string","nullable":true,"metadata":{}},{"name":"bathrooms","type":"string","nullable":true,"metadata":{}},{"name":"bedrooms","type":"string","nullable":true,"metadata":{}},{"name":"room_type","type":"string","nullable":true,"metadata":{}},{"name":"square_feet","type":"string","nullable":true,"metadata":{}},{"name":"host_is_super_host","type":"string","nullable":true,"metadata":{}},{"name":"city","type":"string","nullable":true,"metadata":{}},{"name":"state","type":"string","nullable":true,"metadata":{}},{"name":"cancellation_policy","type":"string","nullable":true,"metadata":{}},{"name":"security_deposit","type":"string","nullable":true,"metadata":{}},{"name":"cleaning_fee","type":"string","nullable":true,"metadata":{}},{"name":"extra_people","type":"string","nullable":true,"metadata":{}},{"name":"minimum_nights","type":"string","nullable":true,"metadata":{}},{"name":"first_review","type":"string","nullable":true,"metadata":{}},{"name":"instant_bookable","type":"string","nullable":true,"metadata":{}},{"name":"number_of_reviews","type":"string","nullable":true,"metadata":{}},{"name":"review_scores_rating","type":"string","nullable":true,"metadata":{}},{"name":"price_per_bedroom","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null}]},"errorSummary":"java.rmi.RemoteException: com.databricks.backend.daemon.data.common.InvalidMountException: Error while using path /mnt/learningspark/airbnb/airbnb.csv for getFileStatus.; nested exception is: ","error":"<div class=\"ansiout\">\tcom.databricks.backend.daemon.data.common.InvalidMountException: Error while using path /mnt/learningspark/airbnb/airbnb.csv for getFileStatus.\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:100)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:55)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.getFileStatus(DatabricksFileSystemV1.scala:260)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.getFileStatus(DatabricksFileSystem.scala:206)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:694)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$15.apply(DataSource.scala:383)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$15.apply(DataSource.scala:383)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:344)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:382)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:209)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:578)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:450)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-463637603480128:1)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-463637603480128:45)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-463637603480128:47)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$read$$iw$$iw$$iw.&lt;init&gt;(command-463637603480128:49)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$read$$iw$$iw.&lt;init&gt;(command-463637603480128:51)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$read$$iw.&lt;init&gt;(command-463637603480128:53)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$read.&lt;init&gt;(command-463637603480128:55)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$read$.&lt;init&gt;(command-463637603480128:59)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$read$.&lt;clinit&gt;(command-463637603480128)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$eval$.$print(&lt;notebook&gt;:6)\n\tat lineea776c3eba8f4bed9bbdeebeb027141e25.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)\n\tat scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:186)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply$mcV$sp(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:457)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:411)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:235)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:216)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:40)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:40)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:216)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:596)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:554)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: com.databricks.backend.daemon.data.common.InvalidMountException: Error while using path /mnt/learningspark/airbnb/airbnb.csv for getFileStatus.\n\tat com.databricks.backend.daemon.data.common.InvalidMountException$.apply(DataMessages.scala:399)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.getFileStatus(RootFileSystemBackend.scala:65)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler$$anonfun$2.apply(FileSystemRequestHandler.scala:33)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler$$anonfun$2.apply(FileSystemRequestHandler.scala:33)\n\tat com.databricks.logging.UsageLogging$$anonfun$recordOperation$1.apply(UsageLogging.scala:313)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.withAttributionContext(FileSystemRequestHandler.scala:19)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.withAttributionTags(FileSystemRequestHandler.scala:19)\n\tat com.databricks.logging.UsageLogging$class.recordOperation(UsageLogging.scala:298)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.recordOperation(FileSystemRequestHandler.scala:19)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.receive(FileSystemRequestHandler.scala:32)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext$$anonfun$queryHandlers$1.apply(SessionContext.scala:71)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext$$anonfun$queryHandlers$1.apply(SessionContext.scala:70)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:70)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:272)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:252)\n\tat com.databricks.rpc.ServerBackend$$anonfun$internalReceive$1$$anonfun$apply$1.apply(ServerBackend.scala:42)\n\tat com.databricks.rpc.ServerBackend$$anonfun$internalReceive$1$$anonfun$apply$1.apply(ServerBackend.scala:38)\n\tat com.databricks.rpc.ServerBackend$$anonfun$com$databricks$rpc$ServerBackend$$commonReceive$1.applyOrElse(ServerBackend.scala:58)\n\tat com.databricks.rpc.ServerBackend$$anonfun$com$databricks$rpc$ServerBackend$$commonReceive$1.applyOrElse(ServerBackend.scala:58)\n\tat com.databricks.rpc.ServerBackend$$anonfun$internalReceive$1.apply(ServerBackend.scala:38)\n\tat com.databricks.logging.UsageLogging$$anonfun$recordOperation$1.apply(UsageLogging.scala:313)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:13)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:13)\n\tat com.databricks.logging.UsageLogging$class.recordOperation(UsageLogging.scala:298)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:13)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:37)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$10.apply(JettyServer.scala:285)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:285)\n\tat com.databricks.rpc.JettyServer$RequestManager.com$databricks$rpc$JettyServer$RequestManager$$handleRequestAndRespond(JettyServer.scala:220)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$handleHttp$1.apply$mcV$sp(JettyServer.scala:154)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$handleHttp$1.apply(JettyServer.scala:145)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$handleHttp$1.apply(JettyServer.scala:145)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.rpc.JettyServer$.withAttributionContext(JettyServer.scala:81)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.rpc.JettyServer$.withAttributionTags(JettyServer.scala:81)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:144)\n\tat com.databricks.rpc.JettyServer$RequestManager.doGet(JettyServer.scala:99)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:845)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:524)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:319)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:253)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.Throwable: Forbidden (Service: Amazon S3; Status Code: 403; Error Code: 403 Forbidden; Request ID: F94D711B6E2AAC69)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1588)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1258)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1030)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:742)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:716)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:699)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:667)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:649)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:513)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4169)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4116)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1237)\n\tat com.databricks.s3a.aws.EnforcingDatabricksS3Client.getObjectMetadata(EnforcingDatabricksS3Client.scala:190)\n\tat com.databricks.s3a.S3AFileSystem.getFileStatus(S3AFileSystem.java:1219)\n\tat com.databricks.s3a.S3AFileSystem.getFileStatus(S3AFileSystem.java:78)\n\tat com.databricks.backend.daemon.data.server.backend.HadoopFSBackend.getFileStatus(HadoopFSBackend.scala:42)\n\tat com.databricks.backend.daemon.data.server.backend.RootFileSystemBackend.getFileStatus(RootFileSystemBackend.scala:55)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler$$anonfun$2.apply(FileSystemRequestHandler.scala:33)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler$$anonfun$2.apply(FileSystemRequestHandler.scala:33)\n\tat com.databricks.logging.UsageLogging$$anonfun$recordOperation$1.apply(UsageLogging.scala:313)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.withAttributionContext(FileSystemRequestHandler.scala:19)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.withAttributionTags(FileSystemRequestHandler.scala:19)\n\tat com.databricks.logging.UsageLogging$class.recordOperation(UsageLogging.scala:298)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.recordOperation(FileSystemRequestHandler.scala:19)\n\tat com.databricks.backend.daemon.data.server.handler.FileSystemRequestHandler.receive(FileSystemRequestHandler.scala:32)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext$$anonfun$queryHandlers$1.apply(SessionContext.scala:71)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext$$anonfun$queryHandlers$1.apply(SessionContext.scala:70)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:70)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:272)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:252)\n\tat com.databricks.rpc.ServerBackend$$anonfun$internalReceive$1$$anonfun$apply$1.apply(ServerBackend.scala:42)\n\tat com.databricks.rpc.ServerBackend$$anonfun$internalReceive$1$$anonfun$apply$1.apply(ServerBackend.scala:38)\n\tat com.databricks.rpc.ServerBackend$$anonfun$com$databricks$rpc$ServerBackend$$commonReceive$1.applyOrElse(ServerBackend.scala:58)\n\tat com.databricks.rpc.ServerBackend$$anonfun$com$databricks$rpc$ServerBackend$$commonReceive$1.applyOrElse(ServerBackend.scala:58)\n\tat com.databricks.rpc.ServerBackend$$anonfun$internalReceive$1.apply(ServerBackend.scala:38)\n\tat com.databricks.logging.UsageLogging$$anonfun$recordOperation$1.apply(UsageLogging.scala:313)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:13)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:13)\n\tat com.databricks.logging.UsageLogging$class.recordOperation(UsageLogging.scala:298)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:13)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:37)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$10.apply(JettyServer.scala:285)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:285)\n\tat com.databricks.rpc.JettyServer$RequestManager.com$databricks$rpc$JettyServer$RequestManager$$handleRequestAndRespond(JettyServer.scala:220)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$handleHttp$1.apply$mcV$sp(JettyServer.scala:154)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$handleHttp$1.apply(JettyServer.scala:145)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$handleHttp$1.apply(JettyServer.scala:145)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.rpc.JettyServer$.withAttributionContext(JettyServer.scala:81)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.rpc.JettyServer$.withAttributionTags(JettyServer.scala:81)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:144)\n\tat com.databricks.rpc.JettyServer$RequestManager.doGet(JettyServer.scala:99)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:845)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:524)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:319)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:253)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\tat java.lang.Thread.run(Thread.java:748)</div>","workflows":[],"startTime":1518519768429,"submitTime":1518519768418,"finishTime":1518519778467,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d577344c-9c0b-44c9-b77f-6a430dec37b0"},{"version":"CommandV1","origId":463637603480129,"guid":"0ee29435-1ff3-4a74-b087-4bce7ef1d985","subtype":"command","commandType":"auto","position":2.0,"command":"raw_df.show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+--------------------+-------------------+--------------------+------------+------------+--------------+---------------+----------------+-----------------+--------------------+-----------------+\n|     id|                name|               space|               price|           bathrooms|            bedrooms|           room_type|         square_feet|  host_is_super_host|           city|               state|cancellation_policy|    security_deposit|cleaning_fee|extra_people|minimum_nights|   first_review|instant_bookable|number_of_reviews|review_scores_rating|price_per_bedroom|\n+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+--------------------+-------------------+--------------------+------------+------------+--------------+---------------+----------------+-----------------+--------------------+-----------------+\n|5731498|A 2-bdrm house in...|Ideally located a...|               120.0|                 1.0|                 2.0|     Entire home/apt|                null|                 0.0|         Athina|                null|           moderate|               200.0|        20.0|        15.0|             2|     2015-04-07|             1.0|               16|                94.0|             60.0|\n|1108690|Just 200m from Ac...|Sunny &amp; Quiet apa...|                42.0|                 1.0|                 1.0|     Entire home/apt|                null|                 0.0|         Athens|              Attica|             strict|                 0.0|         0.0|        17.0|             1|     2013-05-15|             0.0|              189|                86.0|             42.0|\n|1286210|Zen space near ce...|JUST REFURBISHED ...|                48.0|                 1.0|                 1.0|     Entire home/apt|                null|                 0.0|         Athens|              Attica|           moderate|                 0.0|        10.0|         0.0|             1|     2013-12-14|             0.0|                4|               100.0|             48.0|\n| 918812|Athens Soul Apart...|This 30m2 flat on...|                40.0|                 1.0|                 1.0|     Entire home/apt|               323.0|                 0.0|         Athens|              Attica|           moderate|                 0.0|        10.0|         0.0|             3|     2013-03-25|             0.0|              102|                95.0|             40.0|\n| 240960|ATHENS DESIGNER'S...|&quot;Designer's down ...| famous for it's ...| the best market ...|                70.0|                 1.0|                 1.0|     Entire home/apt|           null|                 0.0|             Athens|              Attica|      strict|       200.0|          30.0|           10.0|               2|       2012-10-09|                 0.0|               22|\n| 587782|Breath Away Natio...|A breath away fro...|                40.0|                 1.0|                 1.0|     Entire home/apt|                null|                 0.0|         Athens|                null|           flexible|                90.0|        20.0|         0.0|             3|     2013-01-05|             0.0|               15|                83.0|             40.0|\n|1116076|    Central Location|Spacious first fl...|                70.0|                 1.5|                 2.0|     Entire home/apt|                 0.0|                 0.0|         Athens|              Attica|             strict|                 0.0|        30.0|        10.0|             2|     2013-06-04|             0.0|               37|                95.0|             35.0|\n|1824675|Your room in the ...|The house is loca...|                45.0|                 1.5|                 1.0|        Private room|                null|                 0.0|         Athens|              Attica|           moderate|                 0.0|        15.0|        15.0|             1|     2013-11-05|             0.0|              129|                94.0|             45.0|\n| 360940|Vintage Design Fl...|&quot;the.flat |  A hi...|  two large bedrooms| kitchen (refrige...|           mini oven| coffee maker and...| a bathroom with ...| a w.c. and a lar...| grocery stores| a National Bank ...|         drugstores| parking stations...|        65.0|         1.5|           2.0|Entire home/apt|          1292.0|              0.0|              Athens|           Attica|\n| 110085|ROCK APARTMENTS -...|BEST VALUE FOR MO...|                59.0|                 1.0|                 2.0|     Entire home/apt|                null|                 0.0|          Vyron|              Attica|           flexible|                 0.0|         0.0|         0.0|             5|     2011-05-29|             0.0|                3|                67.0|             29.5|\n| 110066|ROCK APARTMENTS -...|BEST VALUE FOR MO...|                29.0|                 1.0|                 1.0|     Entire home/apt|                 0.0|                 0.0|          Vyron|              Attica|           flexible|                 0.0|         0.0|         0.0|             5|     2011-06-30|             0.0|                4|               100.0|             29.0|\n| 932359|25min. walking di...| A noiseless apar...|                19.0|                 1.0|                 2.0|     Entire home/apt|                null|                 0.0|         Athens|              Attica|           flexible|                 0.0|         0.0|        10.0|             7|     2013-04-30|             0.0|               31|                90.0|              9.5|\n| 155271|STYLISH APARTMENT...|Family owned apar...|                59.0|                 1.0|                 1.0|     Entire home/apt|               538.0|                 1.0|         Athens|                null|           moderate|                 0.0|        28.0|        14.0|             2|     2011-07-04|             0.0|              129|                97.0|             59.0|\n|3326903|Newly decorated b...|The apartment is ...|                60.0|                 1.0|                 2.0|     Entire home/apt|                null|                 0.0|       Zografou|                null|             strict|               100.0|        60.0|         0.0|             3|     2014-12-18|             0.0|                9|               100.0|             30.0|\n|1272844|Small hostel with...|Mets s the cooles...|                35.0|                 1.0|                 1.0|     Entire home/apt|               269.0|                 0.0|         Athens|              Attica|           flexible|                 0.0|         0.0|        10.0|             3|     2013-08-11|             0.0|               43|                85.0|             35.0|\n|5246919|Acropolis with a ...| Spectacular view...|                35.0|                 1.0|                 1.0|        Private room|                null|                 0.0|         Athina|                null|           flexible|                 0.0|         0.0|         0.0|             1|     2015-04-09|             0.0|                5|                96.0|             35.0|\n|1050677|New cosy apartmen...|My apartment is n...|                30.0|                 1.0|                 1.0|     Entire home/apt|                null|                 1.0|         Athens|              Attica|           moderate|                 0.0|        20.0|         0.0|             2|     2013-06-18|             0.0|               68|                97.0|             30.0|\n|2423058|Traditional islan...|&quot;It's a &quot;&quot;traditi...| in a central &amp; q...| a kitchen and a ...| all connected by...|     comfy to cook.&quot;|                20.0|                 1.0|            2.0|     Entire home/apt|               null|                 0.0|      Athens|      Attica|      moderate|            0.0|            15.0|             15.0|                   2|       2014-03-24|\n|6781997|Acropolis Stunnin...|The flat is very ...|                78.0|                 1.0|                 2.0|     Entire home/apt|                null|                 0.0|         Athens|              Greece|           flexible|                 0.0|         0.0|         0.0|             2|     2015-07-01|             1.0|                1|               100.0|             39.0|\n|6457016|    Room with a view|                null|                50.0|                 1.0|                 1.0|        Private room|                null|                 0.0|         Athina|                null|           moderate|                 0.0|         0.0|         0.0|             1|     2015-06-09|             1.0|                5|               100.0|             50.0|\n+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+--------------------+-------------------+--------------------+------------+------------+--------------+---------------+----------------+-----------------+--------------------+-----------------+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1518519784799,"submitTime":1518519784788,"finishTime":1518519788896,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7f5b67b4-0784-4ed1-a3b5-5b301d83ab9f"},{"version":"CommandV1","origId":463637603480130,"guid":"01cb733b-b535-42c2-b9fc-89b12bf85da8","subtype":"command","commandType":"auto","position":3.0,"command":"raw_df.columns.size","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">res2: Int = 21\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496742946661,"submitTime":1496742946650,"finishTime":1496742946827,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b867809d-726e-4754-9145-502876b60d21"},{"version":"CommandV1","origId":463637603480131,"guid":"7e6e388e-9b21-482c-afc9-0c67dfa3c6aa","subtype":"command","commandType":"auto","position":4.0,"command":"raw_df.printSchema()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- space: string (nullable = true)\n |-- price: string (nullable = true)\n |-- bathrooms: string (nullable = true)\n |-- bedrooms: string (nullable = true)\n |-- room_type: string (nullable = true)\n |-- square_feet: string (nullable = true)\n |-- host_is_super_host: string (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n |-- cancellation_policy: string (nullable = true)\n |-- security_deposit: string (nullable = true)\n |-- cleaning_fee: string (nullable = true)\n |-- extra_people: string (nullable = true)\n |-- minimum_nights: string (nullable = true)\n |-- first_review: string (nullable = true)\n |-- instant_bookable: string (nullable = true)\n |-- number_of_reviews: string (nullable = true)\n |-- review_scores_rating: string (nullable = true)\n |-- price_per_bedroom: string (nullable = true)\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496747039168,"submitTime":1496747039157,"finishTime":1496747039246,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"54a480a7-877f-431c-83c9-f4fa28f1688e"},{"version":"CommandV1","origId":463637603480132,"guid":"e133d45b-7600-43ba-b530-9a6cc08f3adb","subtype":"command","commandType":"auto","position":5.21875,"command":"val df = raw_df.withColumn(\"price_new\",raw_df.col(\"price\").cast(\"int\")).drop(\"price\").withColumnRenamed(\"price_new\", \"price\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">df: org.apache.spark.sql.DataFrame = [id: int, name: string ... 19 more fields]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:42: error: not found: value df_1\n       val df_2 = raw_df.withColumn(&quot;price_new&quot;,df_1.col(&quot;price&quot;).cast(&quot;int&quot;))\n                                                ^\n</div>","error":null,"workflows":[],"startTime":1496747040149,"submitTime":1496747040139,"finishTime":1496747040269,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8530a59e-17f1-4670-8088-a55905c61fdf"},{"version":"CommandV1","origId":463637603480133,"guid":"f6e485f1-7e0f-4103-a080-5a5bc9860af6","subtype":"command","commandType":"auto","position":5.3125,"command":"df.printSchema()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- space: string (nullable = true)\n |-- bathrooms: string (nullable = true)\n |-- bedrooms: string (nullable = true)\n |-- room_type: string (nullable = true)\n |-- square_feet: string (nullable = true)\n |-- host_is_super_host: string (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n |-- cancellation_policy: string (nullable = true)\n |-- security_deposit: string (nullable = true)\n |-- cleaning_fee: string (nullable = true)\n |-- extra_people: string (nullable = true)\n |-- minimum_nights: string (nullable = true)\n |-- first_review: string (nullable = true)\n |-- instant_bookable: string (nullable = true)\n |-- number_of_reviews: string (nullable = true)\n |-- review_scores_rating: string (nullable = true)\n |-- price_per_bedroom: string (nullable = true)\n |-- price: integer (nullable = true)\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496747041044,"submitTime":1496747041033,"finishTime":1496747041112,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"48282b7f-0f74-4403-b1b0-4051fd9b4399"},{"version":"CommandV1","origId":463637603480134,"guid":"27ec7dd7-14e7-4637-95e5-0bf98ae2ab23","subtype":"command","commandType":"auto","position":5.5,"command":"println(\"Number of rows in dataframe = \" + df.count())","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Number of rows in dataframe = 198455\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496747042009,"submitTime":1496747041998,"finishTime":1496747042248,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2d22baf7-200b-489b-ac9b-19c3e75c9459"},{"version":"CommandV1","origId":463637603480135,"guid":"01a93291-6ac0-4163-a893-5b6c38c88742","subtype":"command","commandType":"auto","position":6.0,"command":"val filtered_df_1  = raw_df.select(\"id\", \"space\", \"room_type\", \"price\").filter($\"price\".between(50,750)).filter($\"bathrooms\"> 0.0)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">filtered_df_1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: int, space: string ... 2 more fields]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496747172310,"submitTime":1496747172303,"finishTime":1496747172404,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"dca03c61-c5de-4843-8c7e-9ed2e6dcda16"},{"version":"CommandV1","origId":463637603480136,"guid":"398759dc-ae8e-4f2e-b190-fe50876b4e2e","subtype":"command","commandType":"auto","position":7.0,"command":"println(\"Number of rows in filter_df_1 dataframe = \" + filtered_df_1.count())","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Number of rows in filter_df_1 dataframe = 152220\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:40: error: not found: value filtered_df1\n              println(&quot;Number of rows in filter_df_1 dataframe = &quot; + filtered_df1.count())\n                                                                     ^\n</div>","error":null,"workflows":[],"startTime":1496747189898,"submitTime":1496747189891,"finishTime":1496747190096,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4440034d-680f-40b2-9616-78e7d2e4c0e8"},{"version":"CommandV1","origId":463637603480137,"guid":"17d48c8b-6298-444e-986a-18ac028f2dcd","subtype":"command","commandType":"auto","position":8.0,"command":"val filtered_df2  = raw_df.select(\"id\", \"space\", \"room_type\", \"price\").filter(\"price >= 50 AND price <= 750 and bathrooms > 0.0\")\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">filtered_df2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: int, space: string ... 2 more fields]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:42: error: org.apache.spark.sql.types.IntegerType.type does not take parameters\n       val filter_df_2  = raw_df.select(&quot;id&quot;, &quot;space&quot;, &quot;room_type&quot;, &quot;price&quot;).filter($&quot;price&quot;.between(50,750)).filter($&quot;bathrooms&quot;.cast(IntegerType())&gt; 0)\n                                                                                                                                                  ^\n</div>","error":null,"workflows":[],"startTime":1496747182520,"submitTime":1496747182513,"finishTime":1496747182612,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0af55bdb-cdbf-4d79-8e36-b75f8d65aaf9"},{"version":"CommandV1","origId":463637603480138,"guid":"b132c50e-3b4a-4579-ba78-8d93f3c3e22e","subtype":"command","commandType":"auto","position":9.0,"command":"println(\"Number of rows in filter_df_2 dataframe = \" + filtered_df_2.count())","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Number of rows in filter_df_2 dataframe = 152220\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496747182991,"submitTime":1496747182984,"finishTime":1496747183190,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fae199ae-8afe-456b-8edc-ebc2778b2883"},{"version":"CommandV1","origId":463637603480139,"guid":"fb1c6cbc-dd9d-41fe-9c78-04f4e5b9ecd5","subtype":"command","commandType":"auto","position":9.5,"command":"val distinct_state  = raw_df.select(\"state\").distinct()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">distinct_state: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [state: string]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:46: error: not found: value distinct_count\nval $ires12 = distinct_count\n              ^\n&lt;console&gt;:42: error: not found: value distinct_count\n       distinct_count  = raw_df.select(&quot;state&quot;).distinct()\n       ^\n</div>","error":null,"workflows":[],"startTime":1496748125793,"submitTime":1496748125787,"finishTime":1496748125861,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5683624a-644e-41a4-adc3-920283340175"},{"version":"CommandV1","origId":463637603480140,"guid":"9bbc9831-97ef-49dd-9b91-a510c8175536","subtype":"command","commandType":"auto","position":9.75,"command":"distinct_state.count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">res48: Long = 4321\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496748137506,"submitTime":1496748137488,"finishTime":1496748138421,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"74fed2dc-b9a6-49ce-bc3e-d49f35365a5c"},{"version":"CommandV1","origId":463637603480141,"guid":"11e32265-40da-40a4-b48f-8143ef7c17c2","subtype":"command","commandType":"auto","position":9.875,"command":"distinct_state.show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+--------------------+\n|               state|\n+--------------------+\n|             Attoikh|\n|      Brunswick West|\n|               373.0|\n|             Antwerp|\n| cutlery and plat...|\n| breakfast nook area|\n| etc **Payment: B...|\n| so it's perfect ...|\n| you will step on...|\n|               247.0|\n| electricity and ...|\n|   1013 AK Amsterdam|\n|oven and stove . ...|\n|               102.0|\n| board &amp; card gam...|\n| vacation or medi...|\n| an open dining r...|\n|     etc. The sheets|\n|              Венето|\n| lontano dai circ...|\n+--------------------+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496748151527,"submitTime":1496748151516,"finishTime":1496748151880,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8f3da45c-f3ab-4abf-93da-6653b75e3bfa"},{"version":"CommandV1","origId":463637603480142,"guid":"2d3b3afc-07d4-4d4b-804b-8cf21ec10ab1","subtype":"command","commandType":"auto","position":10.0,"command":"raw_df.createOrReplaceTempView(\"df\")\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496748991594,"submitTime":1496748991588,"finishTime":1496748991652,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c359ea0e-509f-4d75-9fab-eb39e3ca6578"},{"version":"CommandV1","origId":463637603480143,"guid":"f4fe9e00-6708-4ce5-9226-445fc5a7a3c6","subtype":"command","commandType":"auto","position":10.25,"command":"raw_df.printSchema()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- space: string (nullable = true)\n |-- price: string (nullable = true)\n |-- bathrooms: string (nullable = true)\n |-- bedrooms: string (nullable = true)\n |-- room_type: string (nullable = true)\n |-- square_feet: string (nullable = true)\n |-- host_is_super_host: string (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n |-- cancellation_policy: string (nullable = true)\n |-- security_deposit: string (nullable = true)\n |-- cleaning_fee: string (nullable = true)\n |-- extra_people: string (nullable = true)\n |-- minimum_nights: string (nullable = true)\n |-- first_review: string (nullable = true)\n |-- instant_bookable: string (nullable = true)\n |-- number_of_reviews: string (nullable = true)\n |-- review_scores_rating: string (nullable = true)\n |-- price_per_bedroom: string (nullable = true)\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496748998490,"submitTime":1496748998484,"finishTime":1496748998548,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"948998c3-ed4a-4a5a-b842-ceb1ac468d2f"},{"version":"CommandV1","origId":463637603480144,"guid":"ac7f192a-6a1c-47b3-a3db-347163a5c9b4","subtype":"command","commandType":"auto","position":10.5,"command":"val state_after_cleaning = spark.sql(\"\"\"\nselect case when state in('NY', 'CA', 'London', 'Berlin', 'TX' ,'IL', 'OR', 'DC', 'WA') then state else 'Other' end as state from df\"\"\")\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">state_after_cleaning: org.apache.spark.sql.DataFrame = [state: string]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:45: error: not found: value state_after_cleaning\nval $ires13 = state_after_cleaning\n              ^\n&lt;console&gt;:40: error: not found: value state_after_cleaning\nstate_after_cleaning = spark.sql(&quot;&quot;&quot;\n^\n</div>","error":null,"workflows":[],"startTime":1496748277174,"submitTime":1496748277166,"finishTime":1496748277267,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"21a69391-1635-44c1-b310-7acde532636a"},{"version":"CommandV1","origId":463637603480145,"guid":"a7d4089a-bcbb-429b-930b-7734163a8d8c","subtype":"command","commandType":"auto","position":10.75,"command":"state_after_cleaning.columns\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">res50: Array[String] = Array(state)\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496748320919,"submitTime":1496748320909,"finishTime":1496748320981,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f9e7f828-35e6-4ee0-93b0-7092496dd12a"},{"version":"CommandV1","origId":463637603480146,"guid":"bba96008-c54a-4d5c-a5c0-0961b1af69c4","subtype":"command","commandType":"auto","position":10.875,"command":"val distinct_state_after_clearning  = state_after_cleaning.select(\"state\").distinct()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">distinct_state_after_clearning: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [state: string]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496748339167,"submitTime":1496748339156,"finishTime":1496748339236,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"803ee9ce-f643-4b8f-8322-c61b561c80bb"},{"version":"CommandV1","origId":463637603480147,"guid":"f1d14069-7c89-4bba-9d59-26be8cc4b853","subtype":"command","commandType":"auto","position":10.9375,"command":"distinct_state_after_clearning.count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">res51: Long = 10\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496748348169,"submitTime":1496748348156,"finishTime":1496748348897,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a9c07a6c-9255-47b9-94ca-188e4ead0bed"},{"version":"CommandV1","origId":463637603480148,"guid":"cb4d8041-bd8a-40db-a6eb-864eb4ea7384","subtype":"command","commandType":"auto","position":10.96875,"command":"distinct_state_after_clearning.show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+------+\n| state|\n+------+\n|    DC|\n|    OR|\n|Berlin|\n|London|\n|    CA|\n|    IL|\n| Other|\n|    WA|\n|    NY|\n|    TX|\n+------+\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496748382959,"submitTime":1496748382947,"finishTime":1496748383445,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"39e4a53c-0b96-45f9-b437-2effca4a3abe"},{"version":"CommandV1","origId":463637603480149,"guid":"6b01b39b-86e6-4e7b-b7ad-0042f80d2513","subtype":"command","commandType":"auto","position":11.0,"command":"val datasetImputed = spark.sql(\"\"\"\nselect \n  id, \n  city,\n  case when state in('NY', 'CA', 'London', 'Berlin', 'TX' ,'IL', 'OR', 'DC', 'WA') then state else 'Other' end as state,\n  space,\n  price,\n  bathrooms,\n  bedrooms,\n  room_type,\n  host_is_super_host,\n  cancellation_policy,\n  case when security_deposit is null then 0.0 else security_deposit end as security_deposit,\n  price_per_bedroom,\n  case when number_of_reviews is null then 0.0 else number_of_reviews end as number_of_reviews,\n  case when extra_people is null\n            then 0.0\n            else extra_people\n        end as extra_people,\n        instant_bookable,\n        case when cleaning_fee is null\n            then 0.0\n            else cleaning_fee\n        end as cleaning_fee,\n        case when review_scores_rating is null\n            then 80.0\n            else review_scores_rating\n        end as review_scores_rating,\n        case when square_feet is not null and square_feet > 100\n            then square_feet\n            when (square_feet is null or square_feet <=100) and (bedrooms is null or bedrooms = 0)\n            then 350.0\n            else 380 * bedrooms\n        end as square_feet,\n        case when bathrooms >= 2\n            then 1.0\n            else 0.0\n        end as n_bathrooms_more_than_two\nfrom df\n    where bedrooms is not null\n\"\"\")\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">datasetImputed: org.apache.spark.sql.DataFrame = [id: int, city: string ... 17 more fields]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"org.apache.spark.sql.AnalysisException: cannot resolve '`host_is_superhost`' given input columns: [state, security_deposit, instant_bookable, name, host_is_super_host, extra_people, id, number_of_reviews, cleaning_fee, price_per_bedroom, first_review, minimum_nights, review_scores_rating, price, bedrooms, cancellation_policy, space, bathrooms, square_feet, room_type, city]; line 11 pos 2;","error":"<div class=\"ansiout\">'Project [id#7383, city#7392, CASE WHEN state#7393 IN (NY,CA,London,Berlin,TX,IL,OR,DC,WA) THEN state#7393 ELSE Other END AS state#9680, space#7385, price#7386, bathrooms#7387, bedrooms#7388, room_type#7389, 'host_is_superhost, cancellation_policy#7394]\n+- Filter isnotnull(bedrooms#7388)\n   +- SubqueryAlias df\n      +- Relation[id#7383,name#7384,space#7385,price#7386,bathrooms#7387,bedrooms#7388,room_type#7389,square_feet#7390,host_is_super_host#7391,city#7392,state#7393,cancellation_policy#7394,security_deposit#7395,cleaning_fee#7396,extra_people#7397,minimum_nights#7398,first_review#7399,instant_bookable#7400,number_of_reviews#7401,review_scores_rating#7402,price_per_bedroom#7403] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:77)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:74)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:308)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:308)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:307)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionUp$1(QueryPlan.scala:282)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2(QueryPlan.scala:292)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2$1.apply(QueryPlan.scala:296)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:244)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2(QueryPlan.scala:296)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$7.apply(QueryPlan.scala:301)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:301)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:74)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:67)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:67)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:583)</div>","workflows":[],"startTime":1496748939918,"submitTime":1496748939910,"finishTime":1496748940017,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f621c6f4-5115-460f-8141-29abe9c0afad"},{"version":"CommandV1","origId":463637603480150,"guid":"fcd27fec-8146-4851-a84b-3a904c57856e","subtype":"command","commandType":"auto","position":12.0,"command":"datasetImputed.select(\"city\", \"state\").show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+---------------+-----+\n|           city|state|\n+---------------+-----+\n|         Athina|Other|\n|         Athens|Other|\n|         Athens|Other|\n|         Athens|Other|\n|           null|Other|\n|         Athens|Other|\n|         Athens|Other|\n|         Athens|Other|\n| grocery stores|Other|\n|          Vyron|Other|\n|          Vyron|Other|\n|         Athens|Other|\n|         Athens|Other|\n|       Zografou|Other|\n|         Athens|Other|\n|         Athina|Other|\n|         Athens|Other|\n|            2.0|Other|\n|         Athens|Other|\n|         Athina|Other|\n+---------------+-----+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496749099545,"submitTime":1496749099539,"finishTime":1496749099722,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"03660fde-b928-4ac5-b936-c6e828b15d9c"},{"version":"CommandV1","origId":463637603480151,"guid":"5f9aefc2-c0a6-45de-8815-41e24fc460a8","subtype":"command","commandType":"auto","position":13.0,"command":"spark.sql(\"\"\"\n    select \n        state,\n        count(*) as n,\n        cast(avg(price) as decimal(12,2)) as avg_price,\n        max(price) as max_price\n    from df\n    group by state\n    order by count(*) desc\n\"\"\").show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+-------------------+-----+---------+--------------------+\n|              state|    n|avg_price|           max_price|\n+-------------------+-----+---------+--------------------+\n|                 NY|25254|   138.86|               999.0|\n|                 CA|22635|   153.51|               999.0|\n|      Île-de-France|22223|    98.25|               995.0|\n|               null|13686|    96.23|shelving and clos...|\n|             Berlin|11445|    59.73|                99.0|\n|                NSW| 7721|   165.33|               996.0|\n|                VIC| 4916|   131.99|                99.0|\n|      Noord-Holland| 4492|   124.58|                99.0|\n|          Catalunya| 4276|    64.80|                99.0|\n|          Catalonia| 3941|    81.38|                99.0|\n|                 IL| 3893|   135.72|               999.0|\n|                 ON| 3787|   120.81|                99.0|\n|      North Holland| 3707|   131.31|                99.0|\n|             Québec| 3499|    86.25|                98.0|\n|                 TX| 3476|   198.32|               999.0|\n|                 WA| 2940|   125.85|               999.0|\n|                 BC| 2892|   124.58|                99.0|\n|Comunidad de Madrid| 2837|    61.15|                99.0|\n|                 DC| 2718|   133.96|                99.0|\n|             Dublin| 2530|    90.30|                99.0|\n+-------------------+-----+---------+--------------------+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496749146515,"submitTime":1496749146509,"finishTime":1496749148340,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b59c1572-7386-49d3-bd2d-d8ecf4ce93be"},{"version":"CommandV1","origId":463637603480152,"guid":"4256353b-3ae4-40a7-a34c-dd97a7809fd2","subtype":"command","commandType":"auto","position":14.0,"command":"spark.sql(\"\"\"\n    select \n        city,\n        count(*) as n,\n        cast(avg(price) as decimal(12,2)) as avg_price,\n        max(price) as max_price\n    from df \n    where \n    group by city\n    order by avg(price) desc\n   \"\"\").filter($\"n\">25).show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+-------------------+---+---------+---------+\n|               city|  n|avg_price|max_price|\n+-------------------+---+---------+---------+\n|         Palm Beach| 29|   400.48|    901.0|\n|        Watsonville| 41|   313.71|     99.0|\n|             Malibu|149|   313.08|    999.0|\n|             Avalon| 40|   274.28|     91.0|\n|       Avalon Beach| 40|   261.15|     95.0|\n|Rancho Palos Verdes| 40|   248.65|     99.0|\n|    Manhattan Beach|113|   248.58|     99.0|\n|           Capitola| 35|   246.40|     95.0|\n|           Tamarama| 75|   243.51|     99.0|\n|            Newport| 57|   237.51|     95.0|\n|            Balmain| 58|   230.98|     99.0|\n|      Darling Point| 29|   221.52|     80.0|\n|           La Jolla| 55|   220.13|    850.0|\n|        North Bondi|189|   216.72|     99.0|\n|        Middle Park| 35|   211.43|     95.0|\n|             Bronte|149|   208.73|     99.0|\n|           Clovelly| 64|   207.61|    901.0|\n|         Freshwater| 56|   207.48|     97.0|\n|              Manly|297|   206.25|    996.0|\n|             Soquel| 31|   205.84|     95.0|\n+-------------------+---+---------+---------+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:52: error: not found: value n\n   &quot;&quot;&quot;).filter(n &gt;25).show()\n               ^\n</div>","error":null,"workflows":[],"startTime":1496750140167,"submitTime":1496750140160,"finishTime":1496750140821,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3cf7f733-6006-4a37-8be3-48aa7306afef"},{"version":"CommandV1","origId":463637603480153,"guid":"3dbbe7a5-b2e1-45ee-92e2-360a2d358964","subtype":"command","commandType":"auto","position":14.25,"command":"spark.sql(\"\"\"\n    select \n        city,\n        count(*) as n,\n        cast(avg(price) as decimal(12,2)) as avg_price,\n        max(price) as max_price\n    from df \n    where \n    group by city\n    order by avg(price) desc\n    having count(city) >25 \n   \"\"\").show()","commandVersion":0,"state":"error","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"org.apache.spark.sql.catalyst.parser.ParseException: ","error":"<div class=\"ansiout\">mismatched input 'having' expecting {&lt;EOF&gt;, ',', 'LIMIT', 'WINDOW', 'SORT', 'CLUSTER', 'DISTRIBUTE'}(line 11, pos 4)\n\n== SQL ==\n\n    select \n        city,\n        count(*) as n,\n        cast(avg(price) as decimal(12,2)) as avg_price,\n        max(price) as max_price\n    from df \n    where \n    group by city\n    order by avg(price) desc\n    having count(city) &gt;25 \n----^^^\n   \n\n\tat org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:196)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:98)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:45)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:52)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:583)</div>","workflows":[],"startTime":1496750201868,"submitTime":1496750201868,"finishTime":1496750202066,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3b081bb8-4be2-43fb-b6c6-b0c814612dc5"},{"version":"CommandV1","origId":463637603480154,"guid":"055d6f37-58a4-4642-b41b-0462f93ee250","subtype":"command","commandType":"auto","position":14.5,"command":"spark.sql(\"\"\"\n    select \n        city,\n        count(*) as n,\n        cast(avg(price) as decimal(12,2)) as avg_price,\n        max(price) as max_price\n    from df \n    where \n    group by city\n    having count(city) >25 \n   \"\"\").show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+---------------+----+---------+--------------------+\n|           city|   n|avg_price|           max_price|\n+---------------+----+---------+--------------------+\n|        Antwerp| 260|    78.92|                99.0|\n| Brunswick West|  34|    80.85|                97.0|\n|            1.0|1749|     5.00|with custom laven...|\n|South Melbourne| 127|   164.41|                99.0|\n|       Clontarf|  34|   147.35|                99.0|\n|          Glebe|  87|   134.37|                99.0|\n|      Brunswick| 162|    96.54|                99.0|\n|      Hollywood|  34|   184.44|               999.0|\n|    North Bondi| 189|   216.72|                99.0|\n|       Brighton|  51|   144.53|                99.0|\n|         Queens|1188|    90.88|                99.0|\n|    Culver City| 109|   112.43|                99.0|\n|         Swords|  29|    50.24|                75.0|\n|         Bronte| 149|   208.73|                99.0|\n|         Madrid|5327|    62.74|                99.0|\n|         Londra|  35|    68.66|                90.0|\n|           50.0|  28|     null|old aristocratic ...|\n|  St Kilda East|  37|   114.68|                99.0|\n|      microwave|  44|     null|where you will be...|\n|     Double Bay|  48|   173.71|                99.0|\n+---------------+----+---------+--------------------+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1496750208547,"submitTime":1496750208540,"finishTime":1496750208991,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"326475a7-f246-4ded-9140-7b4819fb4e9c"},{"version":"CommandV1","origId":463637603480155,"guid":"c0f27031-78a3-404c-97fd-d8977a25bd09","subtype":"command","commandType":"auto","position":15.0,"command":"%md \nSpark support GROUP BY and HAVING, it doesn't support queries in the form of  GROUP BY ... HAVING ... ORDER BY ..., where both the HAVING and ORDER BY clauses reference aggregate functions and/or grouping keys.\n\nFor example, the following queries work:\n\nSELECT count(value) FROM t GROUP BY key HAVING max(value) > 10;\nSELECT count(value) FROM t GROUP BY key HAVING key > 10;\n\nSELECT count(value) FROM t GROUP BY key ORDER BY max(value);\n\nSELECT count(value) FROM t GROUP BY key ORDER BY key;\n\nBut these don't:\n\nSELECT count(value) FROM t GROUP BY key HAVING max(value) > 10 ORDER BY max(value);\nSELECT count(value) FROM t GROUP BY key HAVING max(value) > 10 ORDER BY key;","commandVersion":0,"state":"error","results":null,"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:3: error: ';' expected but ',' found.\n       Although Spark does support GROUP BY and HAVING, it doesn't support queries in the form of  GROUP BY ... HAVING ... ORDER BY ..., where both the HAVING and ORDER BY clauses reference aggregate functions and/or grouping keys.\n                                                      ^\n&lt;console&gt;:8: error: ';' expected but integer literal found.\n       SELECT count(value) FROM t GROUP BY key HAVING key &gt; 10;\n                                                            ^\n&lt;console&gt;:14: error: ';' expected but symbol literal found.\n       But these don't:\n                    ^\n</div>","error":null,"workflows":[],"startTime":1496750046018,"submitTime":1496750046018,"finishTime":1496750046041,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"70c5a0fa-dd30-4550-a9b3-17671e70b7a5"},{"version":"CommandV1","origId":4217204818225134,"guid":"91ab1e15-65d0-40b2-b7ef-a4d43618c486","subtype":"command","commandType":"auto","position":16.0,"command":"%md Assignments\n\n1.Do Optimization to above code using best practice of apache spark based on problem statement.\n\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"01cb3186-ac64-44b7-acb4-7c70c89b6630"}],"dashboards":[],"guid":"20cca009-1d44-454d-923b-1884aa35c8a4","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/js/metrics-graphics.js"
 onerror="window.mainJsLoadError = true;"></script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
<script>var tableOfContentsCell = {"version":"CommandV1","origId":0,"guid":"048f4026-bc9c-4fd0-aaf2-5f147c4d5a22","subtype":"command","commandType":"auto","position":0.0,"command":"%md [&lsaquo; Back to Table of Contents](index.html)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{}};</script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>